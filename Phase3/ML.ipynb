{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d640645f",
   "metadata": {},
   "source": [
    "### ML predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd834b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (23, 16)\n",
      "\n",
      "Columns: ['tag', 'type', 'options_count', 'has_options', 'keyword_select', 'is_yes_no_question', 'is_consent', 'is_demographic', 'is_required', 'label_length', 'field_id', 'predicted_kind', 'true_kind', 'is_correct', 'rule_based_prediction', 'rule_correct']\n",
      "\n",
      "Baseline accuracy: 73.9%\n",
      "\n",
      "Rule engine accuracy: 87.0%\n",
      "  question_7968651005: Predicted text but was select\n",
      "  question_7968652005: Predicted text but was select\n",
      "  4014112005: Predicted text but was select\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\omgha\\OneDrive\\Documents\\GitHub\\Libaspace-AI-intern-challenge\\Phase2\\dataset_with_rules.csv')\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nBaseline accuracy: {df['is_correct'].mean()*100:.1f}%\")\n",
    "print(f\"\\nRule engine accuracy: {df['rule_correct'].mean()*100:.1f}%\")\n",
    "errors = df[df['rule_correct'] == 0]\n",
    "for idx, row in errors.iterrows():\n",
    "    print(f\"  {row['field_id']}: Predicted {row['rule_based_prediction']} but was {row['true_kind']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dd212c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "options_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_options",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "keyword_select",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_yes_no_question",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_consent",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_demographic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_required",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "field_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_kind",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "true_kind",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_correct",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule_based_prediction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rule_correct",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c88f1fa9-291a-440c-875d-b0f0023861da",
       "rows": [
        [
         "0",
         "input",
         "text",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "10",
         "first_name",
         "text",
         "text",
         "1",
         "text",
         "1"
        ],
        [
         "1",
         "input",
         "text",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "9",
         "last_name",
         "text",
         "text",
         "1",
         "text",
         "1"
        ],
        [
         "2",
         "input",
         "text",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "5",
         "email",
         "text",
         "text",
         "1",
         "text",
         "1"
        ],
        [
         "3",
         "input",
         "text",
         "2",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "8",
         "country",
         "select",
         "select",
         "1",
         "select",
         "1"
        ],
        [
         "4",
         "input",
         "tel",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "5",
         "phone",
         "text",
         "text",
         "1",
         "text",
         "1"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>type</th>\n",
       "      <th>options_count</th>\n",
       "      <th>has_options</th>\n",
       "      <th>keyword_select</th>\n",
       "      <th>is_yes_no_question</th>\n",
       "      <th>is_consent</th>\n",
       "      <th>is_demographic</th>\n",
       "      <th>is_required</th>\n",
       "      <th>label_length</th>\n",
       "      <th>field_id</th>\n",
       "      <th>predicted_kind</th>\n",
       "      <th>true_kind</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>rule_based_prediction</th>\n",
       "      <th>rule_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input</td>\n",
       "      <td>text</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>first_name</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input</td>\n",
       "      <td>text</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>last_name</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input</td>\n",
       "      <td>text</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>email</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input</td>\n",
       "      <td>text</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>country</td>\n",
       "      <td>select</td>\n",
       "      <td>select</td>\n",
       "      <td>1</td>\n",
       "      <td>select</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input</td>\n",
       "      <td>tel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>phone</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tag  type  options_count  ...  is_correct  rule_based_prediction  rule_correct\n",
       "0  input  text              0  ...           1                   text             1\n",
       "1  input  text              0  ...           1                   text             1\n",
       "2  input  text              0  ...           1                   text             1\n",
       "3  input  text              2  ...           1                 select             1\n",
       "4  input   tel              0  ...           1                   text             1\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bfc2e",
   "metadata": {},
   "source": [
    "### Prepare Features for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6063acfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 features:\n",
      "  1. options_count\n",
      "  2. has_options\n",
      "  3. is_yes_no_question\n",
      "  4. keyword_select\n",
      "  5. is_required\n",
      "  6. label_length\n",
      "\n",
      "Feature matrix shape: (23, 6)\n",
      "Target shape: (23,)\n",
      "\n",
      "Target distribution:\n",
      "true_kind\n",
      "select    12\n",
      "text      11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature statistics:\n",
      "       options_count  has_options  ...  is_required  label_length\n",
      "count      23.000000    23.000000  ...         23.0     23.000000\n",
      "mean        0.521739     0.260870  ...          1.0     19.130435\n",
      "std         0.897956     0.448978  ...          0.0     12.491104\n",
      "min         0.000000     0.000000  ...          1.0      4.000000\n",
      "25%         0.000000     0.000000  ...          1.0      8.000000\n",
      "50%         0.000000     0.000000  ...          1.0     16.000000\n",
      "75%         1.000000     0.500000  ...          1.0     27.000000\n",
      "max         2.000000     1.000000  ...          1.0     45.000000\n",
      "\n",
      "[8 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    'options_count',     #How many options\n",
    "    'has_options',       #Has options flag\n",
    "    'is_yes_no_question',#Yes/No label\n",
    "    'keyword_select',    #Select Keyword\n",
    "    'is_required',       #Required field\n",
    "    'label_length',      #Length of label\n",
    "    # Additional features can be added here\n",
    "    # 'is_consent'       #Consent keyword flag\n",
    "    # 'is_demographic'   #Demographic keyword flag\n",
    "    ]\n",
    "\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "x = df[feature_cols].copy()\n",
    "y = df['true_kind'].copy()\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {x.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(x.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243a8b9",
   "metadata": {},
   "source": [
    "### Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9327015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled feature statistics:\n",
      "       options_count   has_options  ...  is_required  label_length\n",
      "count   2.300000e+01  2.300000e+01  ...         23.0  2.300000e+01\n",
      "mean   -6.757879e-17 -6.757879e-17  ...          0.0 -9.654113e-18\n",
      "std     1.022475e+00  1.022475e+00  ...          0.0  1.022475e+00\n",
      "min    -5.940885e-01 -5.940885e-01  ...          0.0 -1.238520e+00\n",
      "25%    -5.940885e-01 -5.940885e-01  ...          0.0 -9.110955e-01\n",
      "50%    -5.940885e-01 -5.940885e-01  ...          0.0 -2.562456e-01\n",
      "75%     5.445811e-01  5.445811e-01  ...          0.0  6.441730e-01\n",
      "max     1.683251e+00  1.683251e+00  ...          0.0  2.117585e+00\n",
      "\n",
      "[8 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "x = pd.DataFrame(x_scaled, columns=feature_cols)\n",
    "\n",
    "print(f\"\\nScaled feature statistics:\")\n",
    "print(x.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe47cc",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94b40aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS:\n",
      "Accuracy: 87.0% (20/23)\n",
      "\n",
      "Confidence Statistics:\n",
      "  Mean: 0.824\n",
      "  Min: 0.545\n",
      "  Max: 0.995\n",
      "  Std: 0.124\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      select       1.00      0.75      0.86        12\n",
      "        text       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.87        23\n",
      "   macro avg       0.89      0.88      0.87        23\n",
      "weighted avg       0.90      0.87      0.87        23\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  3]\n",
      " [ 0 11]]\n",
      "\n",
      "Model Coefficients:\n",
      "              feature  coefficient\n",
      "3      keyword_select     0.000000\n",
      "4         is_required     0.000000\n",
      "2  is_yes_no_question    -0.721437\n",
      "0       options_count    -0.745593\n",
      "1         has_options    -0.745593\n",
      "5        label_length    -0.803623\n"
     ]
    }
   ],
   "source": [
    "# Train base model\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='lbfgs',  # Good for small datasets\n",
    "    C=1.0,           # Regularization parameter\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "lr_model.fit(x_scaled, y)\n",
    "\n",
    "# Get predictions and probabilities\n",
    "lr_predictions = lr_model.predict(x_scaled)\n",
    "lr_proba = lr_model.predict_proba(x_scaled)\n",
    "lr_confidence = lr_proba.max(axis=1)  # Max probability for each prediction\n",
    "\n",
    "# Calculate accuracy\n",
    "lr_accuracy = accuracy_score(y, lr_predictions)\n",
    "lr_correct = (lr_predictions == y).sum()\n",
    "\n",
    "print(f\"\\nRESULTS:\")\n",
    "print(f\"Accuracy: {lr_accuracy*100:.1f}% ({int(lr_correct)}/{len(y)})\")\n",
    "print(f\"\\nConfidence Statistics:\")\n",
    "print(f\"  Mean: {lr_confidence.mean():.3f}\")\n",
    "print(f\"  Min: {lr_confidence.min():.3f}\")\n",
    "print(f\"  Max: {lr_confidence.max():.3f}\")\n",
    "print(f\"  Std: {lr_confidence.std():.3f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y, lr_predictions))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y, lr_predictions))\n",
    "\n",
    "print(f\"\\nModel Coefficients:\")\n",
    "coef_df = pd.DataFrame(\n",
    "    {'feature': feature_cols, 'coefficient': lr_model.coef_[0]}\n",
    ").sort_values('coefficient', ascending=False)\n",
    "print(coef_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d09971f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression CV Scores:\n",
      "  Fold 1: 100.0%\n",
      "  Fold 2: 60.0%\n",
      "  Fold 3: 80.0%\n",
      "  Fold 4: 100.0%\n",
      "  Fold 5: 75.0%\n",
      "\n",
      "Mean CV Accuracy: 83.0%\n",
      "Std: 15.4%\n",
      "\n",
      "INTERPRETATION:\n",
      "  Training accuracy: 87.0%\n",
      "  Cross-validation (realistic): 83.0%\n",
      "  Overfitting gap: 4.0%\n",
      "Good generalization!\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lr_cv_scores = cross_val_score(lr_model, x_scaled, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nLogistic Regression CV Scores:\")\n",
    "print(f\"  Fold 1: {lr_cv_scores[0]*100:.1f}%\")\n",
    "print(f\"  Fold 2: {lr_cv_scores[1]*100:.1f}%\")\n",
    "print(f\"  Fold 3: {lr_cv_scores[2]*100:.1f}%\")\n",
    "print(f\"  Fold 4: {lr_cv_scores[3]*100:.1f}%\")\n",
    "print(f\"  Fold 5: {lr_cv_scores[4]*100:.1f}%\")\n",
    "print(f\"\\nMean CV Accuracy: {lr_cv_scores.mean()*100:.1f}%\")\n",
    "print(f\"Std: {lr_cv_scores.std()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nINTERPRETATION:\")\n",
    "print(f\"  Training accuracy: {lr_accuracy*100:.1f}%\")\n",
    "print(f\"  Cross-validation (realistic): {lr_cv_scores.mean()*100:.1f}%\")\n",
    "if lr_accuracy > lr_cv_scores.mean():\n",
    "    gap = (lr_accuracy - lr_cv_scores.mean())*100\n",
    "    print(f\"  Overfitting gap: {gap:.1f}%\")\n",
    "    if gap > 5:\n",
    "        print(f\"Some overfitting, but less severe than trees\")\n",
    "    else:\n",
    "        print(f\"Good generalization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ff420cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Confidence Quality:\n",
      "\n",
      "Confidence Distribution:\n",
      "  0.5-0.6:  2 preds, accuracy    50%\n",
      "  0.6-0.7:  2 preds, accuracy    50%\n",
      "  0.7-0.8:  2 preds, accuracy   100%\n",
      "  0.8-0.9: 11 preds, accuracy    91%\n",
      "  0.9-1.0:  6 preds, accuracy   100%\n",
      "  ≥0.9:  6 preds, accuracy   100%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLogistic Regression Confidence Quality:\")\n",
    "print(f\"\\nConfidence Distribution:\")\n",
    "\n",
    "# Check calibration: do high-confidence predictions have high accuracy?\n",
    "bins = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for i in range(len(bins)-1):\n",
    "    low, high = bins[i], bins[i+1]\n",
    "    mask = (lr_confidence >= low) & (lr_confidence < high)\n",
    "    count = mask.sum()\n",
    "    if count > 0:\n",
    "        correct = (lr_predictions[mask] == y[mask]).sum()\n",
    "        acc = correct / count\n",
    "        print(f\"  {low:.1f}-{high:.1f}: {count:2d} preds, accuracy {acc*100:5.0f}%\")\n",
    "\n",
    "high_conf = (lr_confidence >= 0.9).sum()\n",
    "if high_conf > 0:\n",
    "    high_conf_correct = (lr_predictions[lr_confidence >= 0.9] == y[lr_confidence >= 0.9]).sum()\n",
    "    print(f\"  ≥0.9: {high_conf:2d} preds, accuracy {high_conf_correct/high_conf*100:5.0f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310ea7c",
   "metadata": {},
   "source": [
    "KEY INSIGHT:<br>\n",
    "High confidence ≈ High accuracy (well-calibrated!)<br>\n",
    "This is the property we want in confidence scores.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7bae354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCURACY PROGRESSION:\n",
      "  Phase 1 (Baseline):          73.9% (17/23)\n",
      "  Phase 2 (Rules):             87.0% (20/23)\n",
      "  Phase 3 (Logistic Reg):      87.0% (20/23)\n",
      "\n",
      "CONFIDENCE QUALITY:\n",
      "  Logistic Regression:       0.54-1.00 (well-calibrated)\n"
     ]
    }
   ],
   "source": [
    "# Phase 1 (Baseline)\n",
    "phase1_accuracy = (df['predicted_kind'] == df['true_kind']).mean()\n",
    "phase1_correct = (df['predicted_kind'] == df['true_kind']).sum()\n",
    "\n",
    "# Phase 2 (Rules)\n",
    "phase2_accuracy = df['rule_correct'].mean()\n",
    "phase2_correct = df['rule_correct'].sum()\n",
    "\n",
    "# Phase 3 Models\n",
    "print(f\"\\nACCURACY PROGRESSION:\")\n",
    "print(f\"  Phase 1 (Baseline):        {phase1_accuracy*100:6.1f}% ({int(phase1_correct)}/23)\")\n",
    "print(f\"  Phase 2 (Rules):           {phase2_accuracy*100:6.1f}% ({int(phase2_correct)}/23)\")\n",
    "print(f\"  Phase 3 (Logistic Reg):    {lr_accuracy*100:6.1f}% ({int(lr_correct)}/23)\")\n",
    "\n",
    "print(f\"\\nCONFIDENCE QUALITY:\")\n",
    "print(f\"  Logistic Regression:       {lr_confidence.min():.2f}-{lr_confidence.max():.2f} (well-calibrated)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a447997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = df.copy()\n",
    "results_df['lr_prediction'] = lr_predictions\n",
    "results_df['lr_confidence'] = lr_confidence\n",
    "results_df['lr_correct'] = (lr_predictions == y)\n",
    "\n",
    "# Add probability for each class\n",
    "class_labels = lr_model.classes_\n",
    "for i, label in enumerate(class_labels):\n",
    "    results_df[f'lr_proba_{label}'] = lr_proba[:, i]\n",
    "results_df.to_csv('logistic_regression_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce7d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
